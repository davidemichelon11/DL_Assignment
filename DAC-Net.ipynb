{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidemichelon11/DL_Assignment/blob/main/DAC-Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uY03c6gbuYAT"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4nCxw3XdPwwv"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.models import ResNet18_Weights, ResNet34_Weights, ResNet50_Weights, ResNet101_Weights, ResNet152_Weights\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57Y8geD1uccJ"
      },
      "source": [
        "# Extract data and create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C4tGtJuITp1"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jn9EIurhutPN"
      },
      "outputs": [],
      "source": [
        "!unzip -q -o gdrive/MyDrive/Adaptiope.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GPGsSMGRdHX"
      },
      "outputs": [],
      "source": [
        "classes = [\"/backpack\", \"/bookcase\", \"/car jack\", \"/comb\", \"/crown\", \"/file cabinet\", \"/flat iron\", \"/game controller\", \"/glasses\",\n",
        "           \"/helicopter\", \"/ice skates\", \"/letter tray\", \"/monitor\", \"/mug\", \"/network switch\", \"/over-ear headphones\", \"/pen\",\n",
        "           \"/purse\", \"/stand mixer\", \"/stroller\"]\n",
        "\n",
        "for d, td in zip([\"Adaptiope/product_images\", \"Adaptiope/real_life\"], [\"adaptiope_small/product_images\", \"adaptiope_small/real_life\"]):\n",
        "  os.makedirs(td)\n",
        "  for c in tqdm(classes):\n",
        "    c_path = ''.join((d, c))\n",
        "    c_target = ''.join((td, c))\n",
        "    shutil.copytree(c_path, c_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVrMqpSCyxwl"
      },
      "source": [
        "# Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fkEbfTGVE-0"
      },
      "outputs": [],
      "source": [
        "def get_data(batch_size, product_root, real_root, num_ops=2, magnitude=10):\n",
        "  # resizing and cropping\n",
        "  # prepare data transformations for the train loader\n",
        "  transform = list()\n",
        "  transform.append(T.Resize((256, 256)))                      # resize each PIL image to 256 x 256\n",
        "  transform.append(T.RandomCrop((224, 224)))                 # randomly crop a 224 x 224 patch\n",
        "  transform.append(T.ToTensor())                              # convert Numpy to Pytorch Tensor\n",
        "  transform.append(T.Normalize(mean=[0.485, 0.456, 0.406], \n",
        "                               std=[0.229, 0.224, 0.225]))    # normalize with ImageNet mean\n",
        "  \n",
        "  # compose the above transformations into weak and strong (which has RandAugment in addition)\n",
        "  transform_weak = T.Compose(transform.copy())\n",
        "  transform_strong = T.Compose(transform.copy())                           \n",
        "  transform_strong.transforms.insert(0, T.RandAugment(num_ops, magnitude))\n",
        "    \n",
        "  # load data\n",
        "  dataset_prod = torchvision.datasets.ImageFolder(root=product_root, transform=transform_weak)\n",
        "  dataset_prod_aug = torchvision.datasets.ImageFolder(root=product_root, transform=transform_strong)\n",
        "  dataset_real = torchvision.datasets.ImageFolder(root=real_root, transform=transform_weak)\n",
        "  dataset_real_aug = torchvision.datasets.ImageFolder(root=real_root, transform=transform_strong)\n",
        "  \n",
        "  # create train and test splits (80/20)\n",
        "  num_samples = len(dataset_prod) # same number of samples among datasets\n",
        "  training_samples = int(num_samples * 0.8 + 1)\n",
        "  test_samples = num_samples - training_samples\n",
        "\n",
        "  train_data_prod, test_data_prod = torch.utils.data.random_split(dataset_prod, [training_samples, test_samples], generator=torch.Generator().manual_seed(1))\n",
        "  train_data_prod_aug, test_data_prod_aug = torch.utils.data.random_split(dataset_prod_aug, [training_samples, test_samples], generator=torch.Generator().manual_seed(1))\n",
        "  train_data_real, test_data_real = torch.utils.data.random_split(dataset_real, [training_samples, test_samples], generator=torch.Generator().manual_seed(2))\n",
        "  train_data_real_aug, test_data_real_aug = torch.utils.data.random_split(dataset_real_aug, [training_samples, test_samples], generator=torch.Generator().manual_seed(2))\n",
        "\n",
        "  # initialize sampler to get same data from weak and augment\n",
        "  sampler_prod = torch.utils.data.RandomSampler(train_data_prod, generator=torch.Generator().manual_seed(1))\n",
        "  sampler_prod_aug = torch.utils.data.RandomSampler(train_data_prod_aug, generator=torch.Generator().manual_seed(1))\n",
        "  sampler_real = torch.utils.data.RandomSampler(train_data_real, generator=torch.Generator().manual_seed(2))\n",
        "  sampler_real_aug = torch.utils.data.RandomSampler(train_data_real, generator=torch.Generator().manual_seed(2))\n",
        "\n",
        "  # initialize dataloaders\n",
        "  train_loader_prod = torch.utils.data.DataLoader(train_data_prod, batch_size, sampler=sampler_prod)\n",
        "  test_loader_prod = torch.utils.data.DataLoader(test_data_prod, batch_size, shuffle=False)\n",
        "  train_loader_prod_aug = torch.utils.data.DataLoader(train_data_prod_aug, batch_size, sampler=sampler_prod_aug)\n",
        "  test_loader_prod_aug = torch.utils.data.DataLoader(test_data_prod_aug, batch_size, shuffle=False)\n",
        "  \n",
        "  train_loader_real = torch.utils.data.DataLoader(train_data_real, batch_size, sampler=sampler_real)\n",
        "  test_loader_real = torch.utils.data.DataLoader(test_data_real, batch_size, shuffle=False)\n",
        "  train_loader_real_aug = torch.utils.data.DataLoader(train_data_real_aug, batch_size, sampler=sampler_real_aug)\n",
        "  test_loader_real_aug = torch.utils.data.DataLoader(test_data_real_aug, batch_size, shuffle=False)\n",
        "  \n",
        "  return (train_loader_prod, test_loader_prod), (train_loader_prod_aug, test_loader_prod_aug), (train_loader_real, test_loader_real), (train_loader_real_aug, test_loader_real_aug)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSH5iS7K1C2I"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Channel attention module"
      ],
      "metadata": {
        "id": "LwWTeBXhiU7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_planes, ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        \n",
        "        self.fc1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n",
        "        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)"
      ],
      "metadata": {
        "id": "92eb78XZfVn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BasicBlock and Bottleneck modules of ResNet"
      ],
      "metadata": {
        "id": "Ke2vue9KicqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes,\n",
        "        out_planes,\n",
        "        kernel_size=3,\n",
        "        stride=stride,\n",
        "        padding=1,\n",
        "        bias=False\n",
        "    )\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_attention=True, output_attention=False):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.ca = ChannelAttention(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.output_attention = output_attention\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        if self.use_attention:\n",
        "            out_ca = self.ca(out)\n",
        "            out = residual + out_ca * out\n",
        "        else:\n",
        "            out = residual + out\n",
        "            out_ca = []\n",
        "        out = self.relu(out)\n",
        "        if self.output_attention:\n",
        "            return out, out_ca\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, use_attention=True, output_attention=False):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            planes,\n",
        "            planes,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            planes, planes * self.expansion, kernel_size=1, bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.ca = ChannelAttention(planes * self.expansion)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.output_attention = output_attention\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        if self.use_attention:\n",
        "            out_ca = self.ca(out)\n",
        "            out = residual + out_ca * out\n",
        "        else:\n",
        "            out = residual + out\n",
        "            out_ca = []\n",
        "        out = self.relu(out)\n",
        "        if self.output_attention:\n",
        "            return out, out_ca\n",
        "        else:\n",
        "            return out"
      ],
      "metadata": {
        "id": "rQvfrrXEhXkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet architecture with channel attention"
      ],
      "metadata": {
        "id": "1ziG1Kpfk7tR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIlGuzqLNigi"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers):\n",
        "        self.inplanes = 64\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0], use_attention=False)\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, use_attention=False)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, use_attention=True)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, use_attention=True)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * block.expansion, 1000)\n",
        "\n",
        "        # for m in self.modules():\n",
        "        #     if isinstance(m, nn.Conv2d):\n",
        "        #         nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
        "        #     elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
        "        #         nn.init.constant_(m.weight, 1)\n",
        "        #         nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        self._init_params()\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1, use_attention=True):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.inplanes,\n",
        "                    planes * block.expansion,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, use_attention=use_attention))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            if i == blocks - 1:\n",
        "                layers.append(block(self.inplanes, planes, output_attention=True, use_attention=use_attention))\n",
        "            else:\n",
        "                layers.append(block(self.inplanes, planes, use_attention=use_attention))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _init_params(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(\n",
        "                    m.weight, mode='fan_out', nonlinearity='relu'\n",
        "                )\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def featuremaps(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x, out_ca1 = self.layer1(x)\n",
        "        x, out_ca2 = self.layer2(x)\n",
        "        x, out_ca3 = self.layer3(x)\n",
        "        x, out_ca4 = self.layer4(x)\n",
        "        return x, [out_ca1, out_ca2, out_ca3, out_ca4]\n",
        "\n",
        "    def predictions(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        f, channel_attention = self.featuremaps(x)\n",
        "\n",
        "        v = self.avgpool(f)\n",
        "\n",
        "        out = self.predictions(v)\n",
        "        \n",
        "        return out, v, channel_attention"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get model function"
      ],
      "metadata": {
        "id": "kEw6vzLLlEO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(resnet=18, pretrained=False, num_classes=20):\n",
        "  if resnet == 18:\n",
        "    model = ResNet(block=BasicBlock, layers=[2, 2, 2, 2])\n",
        "    weights = ResNet18_Weights.IMAGENET1K_V1\n",
        "  elif resnet == 34:\n",
        "    model = ResNet(block=BasicBlock, layers=[3, 4, 6, 3])\n",
        "    weights = ResNet34_Weights.IMAGENET1K_V1\n",
        "  elif resnet == 50:\n",
        "    model = ResNet(block=Bottleneck, layers=[3, 4, 6, 3])\n",
        "    weights = ResNet50_Weights.IMAGENET1K_V1\n",
        "  elif resnet == 101:\n",
        "    model = ResNet(block=Bottleneck, layers=[3, 4, 23, 3])\n",
        "    weights = ResNet101_Weights.IMAGENET1K_V1\n",
        "  elif resnet == 152:\n",
        "    model = ResNet(block=Bottleneck, layers=[3, 8, 36, 3])\n",
        "    weights = ResNet152_Weights.IMAGENET1K_V1\n",
        "  else:\n",
        "    print(\"Unable to identify the ResNet architecture\")\n",
        "    return\n",
        "\n",
        "  if pretrained:\n",
        "    model.load_state_dict(weights.get_state_dict(progress=True), strict=False)\n",
        "\n",
        "  model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "4eWYZrEWkYTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpK-Bq6d1FnV"
      },
      "source": [
        "# Specify optimizer and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMpc8dxrMmWc"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, lr, wd=0, momentum=0, opt='Adam'):\n",
        "  if opt == 'Adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  elif opt == 'SGD':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n",
        "  \n",
        "  return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_scheduler(optimizer, epochs, sched='cosine'):\n",
        "  if sched == 'cosine':\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "  \n",
        "  return scheduler"
      ],
      "metadata": {
        "id": "npm-U0u-FtTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_I6N6U81MDA"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model, source_train_loader, target_train_loader, \n",
        "                  optimizer, device='cuda:0', show_img=False):\n",
        "  \n",
        "  source_train_loader, source_train_loader_aug = source_train_loader\n",
        "  target_train_loader, target_train_loader_aug = target_train_loader\n",
        "\n",
        "  source_samples = 0.\n",
        "  target_samples = 0.\n",
        "  cumulative_ce_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  conf_threshold = 0.95\n",
        "  weight_strong = 1.\n",
        "\n",
        "  mloss_source = torch.zeros(1)\n",
        "  mloss_strong = torch.zeros(1)\n",
        "\n",
        "  if show_img:\n",
        "    mean = np.array([0.485, 0.456, 0.406]).reshape(1, 1, 3)\n",
        "    std = np.array([0.229, 0.224, 0.225]).reshape(1, 1, 3)\n",
        "  \n",
        "  target_iter = iter(target_train_loader)\n",
        "  target_iter_aug = iter(target_train_loader_aug)\n",
        "\n",
        "  # strictly needed if network contains layers which has different behaviours between train and test\n",
        "  model.train()\n",
        "\n",
        "  pbar = tqdm(zip(source_train_loader, source_train_loader_aug), total=len(source_train_loader))\n",
        "\n",
        "  for i, ((inputs_source, targets_source), (inputs_source_aug, _)) in enumerate(pbar):\n",
        "    \n",
        "    # get target data. If the target iterator reaches the end, restart it\n",
        "    try:\n",
        "      inputs_target, _ = next(target_iter)\n",
        "      inputs_target_aug, _ = next(target_iter_aug)\n",
        "    except:\n",
        "      target_iter = iter(target_train_loader)\n",
        "      target_iter_aug = iter(target_train_loader_aug)\n",
        "\n",
        "      inputs_target, _ = next(target_iter)\n",
        "      inputs_target_aug, _ = next(target_iter_aug)\n",
        "\n",
        "    input_weak = torch.cat([inputs_source, inputs_target], dim=0) \n",
        "    input_strong = torch.cat([inputs_source_aug, inputs_target_aug], dim=0)\n",
        "\n",
        "    targets_domain = torch.cat(\n",
        "        (torch.zeros(inputs_source.shape[0]), torch.ones(inputs_target.shape[0]))\n",
        "    ).unsqueeze(dim=1)\n",
        "\n",
        "    # load data into device\n",
        "    inputs_source, inputs_target, input_weak, input_strong = inputs_source.to(device), inputs_target.to(device), input_weak.to(device), input_strong.to(device)\n",
        "    inputs_target_aug = inputs_target_aug.to(device)\n",
        "    targets_source, targets_domain = targets_source.to(device), targets_domain.to(device)\n",
        "\n",
        "    # Supervised loss\n",
        "    output_source, _, source_ca = model(inputs_source)\n",
        "    loss_source = F.cross_entropy(output_source, targets_source)\n",
        "\n",
        "    # Generate artificial label\n",
        "    with torch.no_grad():\n",
        "      output_weak, _, _ = model(inputs_target)\n",
        "      max_prob, label_weak = F.softmax(output_weak, dim=1).max(dim=1)\n",
        "      mask_conf = (max_prob >= conf_threshold).float()\n",
        "\n",
        "    # Unsupervised loss\n",
        "    output_strong, feat_strong, strong_ca = model(inputs_target_aug)\n",
        "    loss_strong = F.cross_entropy(output_strong, label_weak, reduction='none')\n",
        "    loss_strong = (loss_strong * mask_conf).mean()\n",
        "\n",
        "    loss = loss_source + loss_strong * weight_strong\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "    \n",
        "    # reset the optimizer\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # print statistics\n",
        "    source_samples += inputs_source.shape[0]\n",
        "    target_samples += inputs_target.shape[0]\n",
        "    \n",
        "    cumulative_ce_loss += loss_source.item()\n",
        "    _, predicted = F.softmax(output_source, dim=1).max(dim=1)\n",
        "    cumulative_accuracy += predicted.eq(targets_source).sum().item()\n",
        "\n",
        "    mloss_source = (mloss_source * i + loss_source.item()) / (i + 1)\n",
        "    mloss_strong = (mloss_strong * i + loss_strong.item()) / (i + 1)\n",
        "\n",
        "    pbar.set_description(\"Source loss {} | Strong loss {}\".format(round(mloss_source.item(),4), round(mloss_strong.item(),4)))\n",
        "\n",
        "    if show_img and i < 3:\n",
        "      fig = plt.figure()\n",
        "      \n",
        "      ax1 = fig.add_subplot(1,4,1)\n",
        "      ax1.imshow(np.clip(inputs_source[0].permute(1,2,0).cpu() * std + mean, 0, 1))\n",
        "      ax2 = fig.add_subplot(1,4,2)\n",
        "      ax2.imshow(np.clip(inputs_source_aug[0].permute(1,2,0).cpu() * std + mean, 0, 1))\n",
        "      ax3 = fig.add_subplot(1,4,3)\n",
        "      ax3.imshow(np.clip(inputs_target[0].permute(1,2,0).cpu() * std + mean, 0, 1))\n",
        "      ax4 = fig.add_subplot(1,4,4)\n",
        "      ax4.imshow(np.clip(inputs_target_aug[0].permute(1,2,0).cpu() * std + mean, 0, 1))\n",
        "\n",
        "      [axi.set_axis_off() for axi in [ax1, ax2, ax3, ax4]]\n",
        "      plt.show()\n",
        "\n",
        "  return cumulative_ce_loss/source_samples, cumulative_accuracy/source_samples*100"
      ],
      "metadata": {
        "id": "DJAtlKKEFl5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model, target_test_loader, device='cuda:0'):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  # strictly needed if network contains layers which has different behaviours between train and test\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(tqdm(target_test_loader)):\n",
        "\n",
        "      # load data into GPU\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "        \n",
        "      # forward pass\n",
        "      output, _, _ = model(inputs)\n",
        "\n",
        "      # apply the loss\n",
        "      loss = F.cross_entropy(output, targets)\n",
        "\n",
        "      # print statistics\n",
        "      samples += inputs.shape[0]\n",
        "      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n",
        "      _, predicted = F.softmax(output, dim=1).max(dim=1)\n",
        "      cumulative_accuracy += predicted.eq(targets).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, cumulative_accuracy/samples*100"
      ],
      "metadata": {
        "id": "k1brqIylP764"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J359b2Q73hhN"
      },
      "source": [
        "# Execute everything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WmZKxapc4sU"
      },
      "outputs": [],
      "source": [
        "# Initialize random number generator (RNG) seeds https://pytorch.org/docs/stable/notes/randomness.html\n",
        "# cudnn seed 0 settings are slower and more reproducible, else faster and less reproducible\n",
        "seed = 0\n",
        "\n",
        "import torch.backends.cudnn as cudnn\n",
        "import random\n",
        "import numpy as np\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "cudnn.benchmark, cudnn.deterministic = (False, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiR2HcGtM_Am"
      },
      "outputs": [],
      "source": [
        "batch_size = 60\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "learning_rate = 5e-4\n",
        "epochs = 20\n",
        "\n",
        "prod_root = 'adaptiope_small/product_images'\n",
        "real_root = 'adaptiope_small/real_life'\n",
        "\n",
        "dataloaders_prod, dataloaders_prod_aug, dataloaders_real, dataloaders_real_aug= get_data(batch_size, prod_root, real_root)\n",
        "\n",
        "train_loader_prod, test_loader_prod = dataloaders_prod\n",
        "train_loader_prod_aug, test_loader_prod_aug = dataloaders_prod_aug\n",
        "\n",
        "train_loader_real, test_loader_real = dataloaders_real\n",
        "train_loader_real_aug, test_loader_real_aug = dataloaders_real_aug\n",
        "\n",
        "model = get_model(pretrained=True).to(device)\n",
        "\n",
        "# model.load_state_dict(torch.load('./model_weights.pt'))\n",
        "\n",
        "optimizer = get_optimizer(model, learning_rate)\n",
        "\n",
        "scheduler = get_scheduler(optimizer, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9P-pxqnw5T7"
      },
      "outputs": [],
      "source": [
        "for e in range(epochs):\n",
        "  print('Epoch: {}/{}'.format(e+1, epochs))\n",
        "  train_ce_loss, train_accuracy = training_step(\n",
        "    model=model,\n",
        "    source_train_loader=(train_loader_prod, train_loader_prod_aug),\n",
        "    target_train_loader=(train_loader_real, train_loader_real_aug),\n",
        "    optimizer=optimizer,\n",
        "    device=device, \n",
        "    show_img=False\n",
        "  )\n",
        "\n",
        "  scheduler.step()\n",
        "  \n",
        "  test_loss, test_accuracy = test_step(\n",
        "    model=model, \n",
        "    target_test_loader=test_loader_real, \n",
        "    device=device\n",
        "  )\n",
        "  \n",
        "  # print('Train: CE loss {:.5f}, Accuracy {:.2f}'.format(train_ce_loss, train_accuracy))\n",
        "  print('Test: CE loss {:.5f}, Accuracy {:.2f}'.format(test_loss, test_accuracy))\n",
        "  print('-----------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFYmoawTReyx"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), './model_weights.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LalwBzQlx1AY"
      },
      "source": [
        "# Accuracy notes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Running experiments with seed = 0, pretrained = True, batch size = 60, optimizer = Adam, learning_rate = 5e-4, scheduler = cosine and epochs = 20.*"
      ],
      "metadata": {
        "id": "pcBgjrkvc7UY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Baseline (source loss): \n",
        "*   DA (source loss + strong loss): \n",
        "*   DA (source loss + strong loss + attn loss): \n",
        "*   DA (source loss + strong loss + attn loss + comp loss): "
      ],
      "metadata": {
        "id": "5rs9aRjQsVud"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "DL_assignment_Giulio.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}